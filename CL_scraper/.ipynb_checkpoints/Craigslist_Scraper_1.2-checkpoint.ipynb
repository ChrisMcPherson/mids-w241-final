{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Craigslist Apartment Scraper\n",
    "\n",
    "The purpose of this script is to pull apartment listings, characteristics, prices, and reply emails from for rent ads on craigslist. We plan to use this information in order to run an experiment to test the impact of including exclamation points on response rates to inquiries sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to query craigslist  \n",
    "\n",
    "This function will allow us to specify a price range, the number of bedrooms, and what craigslist site to query (e.g. Denver, SF, NYC, etc.)  \n",
    "\n",
    "Note that these queries only return a max of 100 results each. Thus, we will want to be specific about the price ranges and bedrooms that we specify so we can maximize the number of listings we are able to capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a function to fetch search results\n",
    "def fetch_search_results(query=None, minAsk=None, maxAsk=None, bedrooms=None, base_URL = None):\n",
    "    search_params = {key: val for key, val in locals().items() if val is not None}\n",
    "    if not search_params:\n",
    "        raise ValueError(\"No valid keywords\")\n",
    "    base = base_URL + '/search/apa'\n",
    "    resp = requests.get(base, params=search_params, timeout=3)\n",
    "    resp.raise_for_status()  # <- no-op if status==200\n",
    "    return resp.content, resp.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test the query function.\n",
    "test1, test2 = fetch_search_results(query = None, minAsk = 1000, maxAsk = 4000, bedrooms = 1, base_URL = 'https://denver.craigslist.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get full URLs and apartment characteristics from query function output  \n",
    "\n",
    "This function will go through each of the listings found from our query and compile a dataset of URLs and apartment characteristics of all the results from the query. We will use the URLs to get the reply email addresses in a later step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to get apartment characteristics from each query result  \n",
    "\n",
    "price, bedrooms, square footage, listing title, posting date / time, and reply linnk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get href - the relative link to the full apartment listing. These relative links are identified by <a> tags\n",
    "#and have the class 'result-title hdrlnk'.\n",
    "def get_href(result):\n",
    "    href = result.find('a', {'class' : 'result-title hdrlnk'})['href']\n",
    "    \n",
    "    if href is None:\n",
    "        href = np.nan\n",
    "    \n",
    "    return href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get posting ID - These IDs are the data-ID portion of  <a> tags with the class 'result-title hdrlnk'.\n",
    "def get_posting_ID(result):\n",
    "    posting_ID = result.find('a', {'class' : 'result-title hdrlnk'})['data-id']\n",
    "    \n",
    "    if posting_ID is None:\n",
    "        posting_ID = np.nan\n",
    "    \n",
    "    return posting_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get price - price can be located by <span> tags of class 'result-price'\n",
    "def get_price(result):\n",
    "    price = result.find('span', {'class' : 'result-price'})\n",
    "    \n",
    "    #convert price to float\n",
    "    if price is not None:\n",
    "        price = float(price.text.strip('$'))\n",
    "        \n",
    "    else:\n",
    "        price = np.nan\n",
    "    \n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get listing title which is identified by the text in the <a> tag with class 'result-title hdrlnk'\n",
    "def get_title(result):\n",
    "    title = result.find('a', {'class' : 'result-title hdrlnk'}).text\n",
    "    \n",
    "    if title is None:\n",
    "        title = np.nan\n",
    "        \n",
    "    return title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the time the listing was posted\n",
    "def get_posting_date(result):\n",
    "    posting_date = result.find('time', {'class' : 'result-date'})['datetime']\n",
    "    \n",
    "    if posting_date is None:\n",
    "        posting_date = np.nan\n",
    "        \n",
    "    return posting_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get bedrooms / sqft which is identified by the <span> tag of class 'housing'\n",
    "def get_bedrooms_sqft_str(result):\n",
    "    bedrooms_sqft = result.find('span', {'class' : 'housing'}).text.strip('\\n')\n",
    "    \n",
    "    if bedrooms_sqft is None:\n",
    "        price = np.nan\n",
    "    \n",
    "    return bedrooms_sqft\n",
    "\n",
    "def get_bedrooms_sqft(bedrooms_sqft):\n",
    "    #*******\n",
    "    #remove the new line characters and white space\n",
    "    p_1 = re.compile('-|\\n|\\s')\n",
    "\n",
    "    bedrooms_sqft = p_1.sub('', bedrooms_sqft)\n",
    "\n",
    "    #*******\n",
    "    #get bedrooms\n",
    "    #compile the regex\n",
    "    bedroom_p = re.compile(r'\\d+(?=br)', re.IGNORECASE)\n",
    "\n",
    "    #get match in the bedroom / sqft string\n",
    "    bedroom_m = bedroom_p.match(bedrooms_sqft)\n",
    "\n",
    "    #get bedrooms\n",
    "    n_bedrooms = float(bedrooms_sqft[bedroom_m.start(): bedroom_m.end()])\n",
    "\n",
    "    #*******\n",
    "    #get square footage\n",
    "    #remove bedrooms\n",
    "    bedrooms_sqft = bedrooms_sqft[bedroom_m.end() + 2:]\n",
    "\n",
    "    #compile the regex\n",
    "    sqft_p = re.compile(r'\\d+(?=ft)', re.IGNORECASE)\n",
    "\n",
    "    #get match in the square footage string\n",
    "    sqft_m = sqft_p.match(bedrooms_sqft)\n",
    "\n",
    "    #get square footage\n",
    "    try:\n",
    "        sqft = float(bedrooms_sqft[sqft_m.start():sqft_m.end()])\n",
    "    \n",
    "    except AttributeError:\n",
    "        sqft = np.nan\n",
    "    \n",
    "    return n_bedrooms, sqft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compile all apartment characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE LEFT OFF HERE  \n",
    "\n",
    "Construct reply address using posting ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compile_listing_URLs(query_result, base_URL):\n",
    "    #parse the results of the query\n",
    "    html = bs4(query_result, 'html.parser')\n",
    "\n",
    "    #get all individual apartments from the query\n",
    "    apt_results = html.find_all('p', attrs={'class' : 'result-info'})\n",
    "\n",
    "    #initialize a list to contain all of the URLs that resulted from the query\n",
    "    apts_results_df = pd.DataFrame(columns = ('base_URL', 'href','posting_ID', 'Listing_Title', 'Bedrooms', 'Sqft', 'Price', 'Posting_Date'))\n",
    "   \n",
    "    #Looop through all of the tags containing the apartments and get the addresses of those individual results.\n",
    "    for apt in range(len(apt_results)):\n",
    "        #use helper functions to get characteristics\n",
    "        href = get_href(apt_results[apt])\n",
    "        posting_ID = get_posting_ID(apt_results[apt])\n",
    "        title = get_title(apt_results[apt])\n",
    "        bedrooms_sqft_str = get_bedrooms_sqft_str(apt_results[apt])\n",
    "        bedrooms, sqft = get_bedrooms_sqft(bedrooms_sqft_str)\n",
    "        price = get_price(apt_results[apt])\n",
    "        posting_date = get_posting_date(apt_results[apt])\n",
    "        #populate the result dataframe with the characteristics\n",
    "        apts_results_df.loc[apt] = [base_URL, href, posting_ID, title, bedrooms, sqft, price, posting_date]\n",
    "\n",
    "    #construct full URL for the listing\n",
    "    apts_results_df['full_URL'] = apts_results_df.apply(lambda row: row['base_URL'] + row['href'], axis = 1)\n",
    "    \n",
    "    #construct reply URL for the listing\n",
    "    apts_results_df['Reply_contact_info_link'] = apts_results_df.apply(lambda row: row['base_URL'] + '/reply/den/apa/' + row['posting_ID'].strip('.html'), axis = 1)\n",
    "    \n",
    "    #delete base URL and href columns\n",
    "    del apts_results_df['base_URL']\n",
    "    del apts_results_df['href']\n",
    "    \n",
    "    return apts_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_ID</th>\n",
       "      <th>Listing_Title</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Sqft</th>\n",
       "      <th>Price</th>\n",
       "      <th>Posting_Date</th>\n",
       "      <th>full_URL</th>\n",
       "      <th>Reply_contact_info_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5995589088</td>\n",
       "      <td>Garden Tub, 24-Hour Fitness Center, Year-Round Hot Tub</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>2017-02-20 20:09</td>\n",
       "      <td>https://denver.craigslist.org/apa/5995589088.html</td>\n",
       "      <td>https://denver.craigslist.org/reply/den/apa/5995589088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6009701108</td>\n",
       "      <td>Move in Special!  Remodeled and Classic Homes Available!</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>2017-02-20 20:08</td>\n",
       "      <td>https://denver.craigslist.org/apa/6009701108.html</td>\n",
       "      <td>https://denver.craigslist.org/reply/den/apa/6009701108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5996260334</td>\n",
       "      <td>Accepts Electronic Payments, Business Center, TV Lounge</td>\n",
       "      <td>1.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>2017-02-20 20:08</td>\n",
       "      <td>https://denver.craigslist.org/apa/5996260334.html</td>\n",
       "      <td>https://denver.craigslist.org/reply/den/apa/5996260334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6009645065</td>\n",
       "      <td>Save up to $1300 for vacation!!!</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>2017-02-20 20:04</td>\n",
       "      <td>https://denver.craigslist.org/apa/6009645065.html</td>\n",
       "      <td>https://denver.craigslist.org/reply/den/apa/6009645065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6003660798</td>\n",
       "      <td>Spacious...Carport Included...Ready Now!</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>2017-02-20 20:03</td>\n",
       "      <td>https://denver.craigslist.org/apa/6003660798.html</td>\n",
       "      <td>https://denver.craigslist.org/reply/den/apa/6003660798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   posting_ID                                             Listing_Title  \\\n",
       "0  5995589088    Garden Tub, 24-Hour Fitness Center, Year-Round Hot Tub   \n",
       "1  6009701108  Move in Special!  Remodeled and Classic Homes Available!   \n",
       "2  5996260334   Accepts Electronic Payments, Business Center, TV Lounge   \n",
       "3  6009645065                          Save up to $1300 for vacation!!!   \n",
       "4  6003660798                  Spacious...Carport Included...Ready Now!   \n",
       "\n",
       "   Bedrooms    Sqft   Price      Posting_Date  \\\n",
       "0       2.0  1032.0  1342.0  2017-02-20 20:09   \n",
       "1       3.0  1496.0  1955.0  2017-02-20 20:08   \n",
       "2       1.0   736.0  1165.0  2017-02-20 20:08   \n",
       "3       2.0  1155.0  1864.0  2017-02-20 20:04   \n",
       "4       2.0  1100.0  1385.0  2017-02-20 20:03   \n",
       "\n",
       "                                            full_URL  \\\n",
       "0  https://denver.craigslist.org/apa/5995589088.html   \n",
       "1  https://denver.craigslist.org/apa/6009701108.html   \n",
       "2  https://denver.craigslist.org/apa/5996260334.html   \n",
       "3  https://denver.craigslist.org/apa/6009645065.html   \n",
       "4  https://denver.craigslist.org/apa/6003660798.html   \n",
       "\n",
       "                                  Reply_contact_info_link  \n",
       "0  https://denver.craigslist.org/reply/den/apa/5995589088  \n",
       "1  https://denver.craigslist.org/reply/den/apa/6009701108  \n",
       "2  https://denver.craigslist.org/reply/den/apa/5996260334  \n",
       "3  https://denver.craigslist.org/reply/den/apa/6009645065  \n",
       "4  https://denver.craigslist.org/reply/den/apa/6003660798  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the compiler function\n",
    "test_compiled_URLs = compile_listing_URLs(query_result = test1, base_URL = 'https://denver.craigslist.org')\n",
    "\n",
    "test_compiled_URLs.head()\n",
    "\n",
    "pd.set_option('display.max_colwidth',1000)\n",
    "\n",
    "test_compiled_URLs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operationalizing Phase  \n",
    "\n",
    "This phase will incorporate the ability to run the scraper across a selection of cities and bedroom and price range specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City to Craigslist URLs Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://denver.craigslist.org\n",
      "https://newyork.craigslist.org\n",
      "https://cleveland.craigslist.org\n",
      "https://sfbay.craigslist.org\n"
     ]
    }
   ],
   "source": [
    "#create city list\n",
    "cities = ['denver', 'newyork', 'cleveland', 'sanfrancisco']\n",
    "\n",
    "#set base craigslist URLs\n",
    "base_URLs = ['https://denver.craigslist.org', 'https://newyork.craigslist.org', 'https://cleveland.craigslist.org', \\\n",
    "             'https://sfbay.craigslist.org']\n",
    "\n",
    "search_URLs = ['https://denver.craigslist.org/search/apa', 'https://newyork.craigslist.org/search/abo', \\\n",
    "               'https://cleveland.craigslist.org/search/apa', 'https://sfbay.craigslist.org/search/sfc/apa']\n",
    "\n",
    "reply_strings = ['/reply/den/apa/', '/reply/nyc/abo/', '/reply/cle/apa/', '/reply/sfo/apa/']\n",
    "\n",
    "city_to_URL_dict = {'base_URL' : base_URLs, 'search_URL' : search_URLs, 'reply_string' : reply_strings}\n",
    "\n",
    "city_to_URL_df = pd.DataFrame(city_to_URL_dict, index = cities)\n",
    "\n",
    "for city in city_to_URL_df.base_URL:\n",
    "    print city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Machine_learning_python2]",
   "language": "python",
   "name": "conda-env-Machine_learning_python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
